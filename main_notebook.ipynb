{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae9e0ed-b3ed-4d02-90de-54f398cb5f1c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adfbe9f-3bbc-442d-ab86-c46b796b5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ed99f-9ff4-4982-a601-c19ecccfcf0d",
   "metadata": {},
   "source": [
    "### Creating the pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef950f2-ab2d-4f9d-8d39-13decf5599f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 200 - Image: torch.Size([3, 500, 500]), Label: 2\n"
     ]
    }
   ],
   "source": [
    "class LymphomaDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.label_folder = label_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_files = natsorted(os.listdir(image_folder))\n",
    "        self.label_files = natsorted(os.listdir(label_folder))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        label_name = os.path.join(self.label_folder, self.label_files[idx])\n",
    "\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = int(self.read_label_file(label_name))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def read_label_file(self, label_path):\n",
    "        # Implement logic to read labels from label files\n",
    "        # For example, if labels are in text files, you can use:\n",
    "        with open(label_path, 'r') as file:\n",
    "            label = file.read().strip()  # Adjust based on your label format\n",
    "        return label\n",
    "\n",
    "# Replace 'your_image_folder' and 'your_label_folder' with the actual paths\n",
    "base_folder = os.getcwd()\n",
    "image_folder = os.path.join(base_folder, \"data\", \"images\")\n",
    "label_folder = os.path.join(base_folder, \"data\", \"labels\")\n",
    "\n",
    "# Define transformation (optional, you can customize it based on your needs)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500, 500)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Instantiate the custom dataset\n",
    "dataset = LymphomaDataset(image_folder, label_folder, transform=transform)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Access a sample from the dataset\n",
    "sample_index = 200\n",
    "sample_image, sample_label = dataset[sample_index]\n",
    "\n",
    "# Print information about the sample\n",
    "print(f\"Sample {sample_index} - Image: {sample_image.size()}, Label: {sample_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9940a0-7181-44d8-bc65-b4efa39c2be6",
   "metadata": {},
   "source": [
    "### Creating the AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50b3d55-6f3b-4f65-ba1f-b3cb0f14669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "alexnet = AlexNet(num_classes = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac8086-e6a5-477a-9e34-6e0e156dc95d",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ee9778-c82e-4b12-ac4c-0ea83ddf1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch: 1, Loss: 1.3677, Accuracy: 0.3717\n",
      "Training - Epoch: 2, Loss: 1.3318, Accuracy: 0.3717\n",
      "Training - Epoch: 3, Loss: 1.3003, Accuracy: 0.3717\n",
      "Training - Epoch: 4, Loss: 1.2732, Accuracy: 0.3717\n",
      "Training - Epoch: 5, Loss: 1.2425, Accuracy: 0.3717\n",
      "Training - Epoch: 6, Loss: 1.1879, Accuracy: 0.3717\n",
      "Training - Epoch: 7, Loss: 1.1272, Accuracy: 0.3503\n",
      "Training - Epoch: 8, Loss: 1.1117, Accuracy: 0.3342\n",
      "Training - Epoch: 9, Loss: 1.1120, Accuracy: 0.3262\n",
      "Training - Epoch: 10, Loss: 1.1077, Accuracy: 0.3449\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "alexnet.to(device) # alexnet to the device, gpu if available\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Set the model to training mode\n",
    "    alexnet.train()\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate training accuracy and loss for the epoch\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "\n",
    "    print(f'Training - Epoch: {epoch + 1}, Loss: {average_loss:.4f}, Accuracy: {train_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91abc5e-e9d2-42f3-abe2-3854f132c9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
